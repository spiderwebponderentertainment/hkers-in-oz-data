name: Scrape ABC EN

on:
  schedule:
    - cron: "25 * * * *"      # 每小時第 25 分跑（避開其它 job）
  workflow_dispatch: {}

# ✅ 跟其他 scraper 用同一個 concurrency group，避免互相撞 push
concurrency:
  group: news-scrapers
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0   # ✅ 需要完整歷史先可以 rebase

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r workers/requirements.txt

      - name: Run scraper
        run: python workers/scrape_abc_en.py

      - name: Configure git
        run: |
          git config user.name "news-bot"
          git config user.email "news-bot@users.noreply.github.com"

      # ✅ 先同步遠端，解決 non-fast-forward
      - name: Pull latest (rebase)
        run: |
          git fetch origin main
          git pull --rebase origin main

      - name: Commit and push (if changed)
        run: |
          git add abc_en.json abc_en.xml || true
          if git diff --cached --quiet; then
            echo "No changes."
          else
            git commit -m "chore: update ABC EN feeds"
            git push origin HEAD:main
          fi
